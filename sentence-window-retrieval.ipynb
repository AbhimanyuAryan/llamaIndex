{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    # input_files = [\"./docs/colbert.pdf\"]\n",
    "    input_files = [\"./docs/PLAID.pdf\", \"./docs/colbert.pdf\", \"./docs/colbert-v2.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this paper, 'maps centroids to their corresponding embedding IDs' refers to the process of assigning each output embedding from the BERT encoder to the nearest centroid. These centroids are essentially representative points in the embedding space. The IDs of these embeddings are then grouped together based on their corresponding centroid. This grouping forms an inverted list, which is saved to disk to support fast nearest-neighbor search. This allows for quick identification of token-level embeddings that are similar to those in a query during the search process.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\"explain 'maps centroids to their corresponding embedding IDs' in this paper\")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt') as f:\n",
    "    for line in f:\n",
    "        eval_questions.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does offline indexing work in ColBert?\n",
      "In ColBERT, offline indexing involves computing and storing document embeddings. This process is designed to isolate most of the computations between queries and documents, which allows for pre-computing document representations. The indexing procedure is straightforward: the system goes over the documents in the collection in batches, runs the document encoder on each batch, and stores the output embeddings for each document. Although this is an offline process, several optimizations are incorporated to enhance the throughput of indexing. These optimizations can significantly reduce the offline cost of indexing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bc02991c0646e1811bae2bc1fbdaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad68e85f2434a7c87d6ab079b22c063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is late interaction?\n",
      "Late interaction is an alternative to the single-vector similarity paradigm in information retrieval. Introduced in the ColBERT model, it involves encoding queries and documents at a finer granularity into multi-vector representations. Relevance is then estimated using interactions between these sets of vectors. In this approach, an embedding is produced for every token in the query and document, and relevance is modeled as the sum of maximum similarities between each query vector and all vectors in the document. This method aims to reduce the burden on the encoder by decomposing relevance modeling into token-level computations. It encodes meaning at the level of tokens and delegates query-document matching to the interaction mechanism. However, this added expressivity comes with a larger space footprint than single-vector models, as it requires storing billions of small vectors for web-scale collections.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4a4c846bad4391b787569c9d7e9960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain Query encoder?\n",
      "The Query Encoder is a component of the ColBERT system that processes textual queries. It tokenizes the query into its BERT-based WordPiece tokens. To distinguish the input sequences that correspond to queries, a special token [Q] is prepended to the query. This process is done before the late interaction stage in the system.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905eb2f8eab2409b805861f48e6d7b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766674fedda34de5b51f4e63116429b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3587c723655843a980071d8769c75544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain Document encoder?\n",
      "A document encoder is a part of the system that processes a document by breaking it down into its constituent tokens. It begins by adding BERT's start token [CLS] and a special token [D] to indicate a document sequence. Unlike queries, documents do not have [mask] tokens appended to them. The input sequence is then passed through BERT and a subsequent linear layer. The document encoder then filters out the embeddings that correspond to punctuation symbols, which are identified through a predefined list. This filtering process is designed to reduce the number of embeddings per document, as it is hypothesized that embeddings of punctuation, even when contextualized, are not necessary for effectiveness. The final output is a bag of embeddings for the document.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f16d75989f4383992981762980feeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8028a2069e014dffa09a619e579efec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain storing document embeddings process?\n",
      "The process of storing document embeddings involves running the document encoder on batches of documents in the collection. The output embeddings for each document are then stored. This process, known as indexing, is done offline. To enhance the throughput of indexing, some simple optimizations are incorporated. The embeddings are then transferred from the CPU to the GPU, which can be the most expensive step in re-ranking with ColBERT. Finally, the output embeddings are normalized so that each has an L2 norm equal to one. This makes the dot-product of any two embeddings equivalent to their cosine similarity, falling in the range of -1 to 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09c00be91648e8b5a19f7fb7903c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Tok-k re-ranking with colbert?\n",
      "Top-k re-ranking with ColBERT is a process where ColBERT is used to rank a small set of k documents (for example, k=1000) given a query. This is typically done after the output of another retrieval model, often a term-based model, or it can be used directly for end-to-end retrieval from a document collection. The process involves loading the indexed document representations into memory, representing each document as a matrix of embeddings. A query is then computed into its bag of contextualized embeddings and the document representations are gathered into a 3-dimensional tensor consisting of k document matrices. This method relies on batch computations to exhaustively score each document.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77b0373b13d4f5ca064198ef82912ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does re-ranking works in colbert?\n",
      "Re-ranking in ColBERT works by leveraging the model on top of a term-based retrieval model. This process involves re-ranking the top results extracted by a bag-of-words retrieval model, which is a common setting for testing and deploying neural ranking models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a491c1fcf79949a183c6a099b5ef933c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain end-to-end retrival with colbert?\n",
      "End-to-end retrieval with ColBERT involves several steps. First, a query and a document are given, represented as q and d respectively. These are then processed to compute the bags of embeddings Eq and Ed. This is done by normalizing the output of a convolutional neural network (CNN) applied to BERT embeddings of the query and document. The document embeddings are further filtered to reduce the number of embeddings per document. \n",
      "\n",
      "The relevance score of the document to the query, denoted as Sq,d, is then estimated through a late interaction between their bags of contextualized embeddings. This interaction is conducted as a sum of maximum similarity computations, such as cosine similarity or squared L2 distance. \n",
      "\n",
      "ColBERT is differentiable end-to-end and is fine-tuned using the Adam optimizer. The interaction mechanism has no trainable parameters. Given a triple with a query, a positive document, and a negative document, ColBERT is used to produce a score for each document individually. The system is optimized via pairwise softmax cross-entropy loss over the computed scores of the positive and negative documents.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc2d7e3f3df42e6882d6893fb13a1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32f337e357d4b29a52101db0aa235d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966ff10927f44aa28508e208ef481525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaac9472fb7b48388da956290f8cf04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781d02d77761463ea40a3abc320f6af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.789756</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.027877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Groundedness  \\\n",
       "app_id                                                         \n",
       "Sentence Window Query Engine            0.9125      0.789756   \n",
       "\n",
       "                              Context Relevance  latency  total_cost  \n",
       "app_id                                                                \n",
       "Sentence Window Query Engine            0.75625     9.25    0.027877  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: 1 args: ['streamlit', 'run', '--server.headless=True', '...>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.789756</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.027877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Groundedness  \\\n",
       "app_id                                                         \n",
       "Sentence Window Query Engine            0.9125      0.789756   \n",
       "\n",
       "                              Context Relevance  latency  total_cost  \n",
       "app_id                                                                \n",
       "Sentence Window Query Engine            0.75625     9.25    0.027877  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
